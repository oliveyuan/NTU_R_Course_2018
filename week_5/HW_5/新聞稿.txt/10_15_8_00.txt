
				「剝離技術和參數等外衣，探求設計與人文的本源。」沒有太多硬體基因的 Google，對智慧手機產品一直有另一番理解，尤其是拍照方面。2016 年 10 月 5 日，Google CEO 桑德爾•皮蔡（Sundar Pichai）提出由「行動優先」轉為「AI 優先」口號，同日亮相的初代 Pixel 手機就是理念的體現。 表面看，Pixel 使用的鏡頭和更早推出的 Nexus 6P 並沒有太多變化，都是一樣的 1,230 萬像素和 1.55μm 單像素大小，區別僅是加入對焦功能。 但兩者卻在<U+00A0>DxOMark<U+00A0>獲得完全不同的評價──Nexus 6P 只有不起眼的 73 分，但 Pixel 卻以<U+00A0>89 分拿下榜首。  之後第二代 Pixel 推出時，Google 也開始把賣點放在拍照，這款手機的評分漲到<U+00A0>98 分，一舉超過同期三星 Galaxy Note 8 和蘋果 iPhone 8 Plus 再度登頂，DxOMark 當時的評語是「創下智慧手機相機品質的新紀錄」。 連續兩次拿下榜首，加上媒體和用戶好評如潮，開始讓 Google 親兒子手機散發出神祕的吸引力。 雖然<U+00A0>DxOMark 得分僅供參考，但最讓人不解的是，兩代 Pixel 手機都僅是單鏡頭就獲得這成績，其他手機基本都是後置雙鏡頭，難道 Google 的 AI 演算法真已強大到無視物理硬體了嗎？ 哪怕是今天，新發表的 Pixel 3 手機也依舊沒有採用主流的雙鏡頭乃至三鏡頭組合，這種「靠單鏡頭獨步天下」的功力，除了 Google 也很難再找到第二家。 但現在來看，Google 確實有這份「任性」的資格和實力。 Pixel 3 的鏡頭有多聰明？ 在用戶的認知中，攝影過程無非 3 個步驟：1.<U+00A0>看到想拍的東西；2. 啟動相機按下快門，記錄瞬間；3. 得到一張靜止不動的照片。 專業攝影師就不一樣了。他們得根據現場光線情況調整快門和光圈，選擇合適焦段的鏡頭，拍攝時會考慮構圖和按快門的時機，拍完還要拿去 PS 或 LR 後製一下，最終才得出外人眼中的各種「大片」。 但智慧手機普及改變了一切，不管<U+00A0>Pixel 還是 iPhone 或其他手機，手機廠商都在淡化原本只有攝影師才懂的 ISO、曝光時間等數值，這些交給處理器和演算法完成就好了，用戶只要按下快門，也能拍出一張媲美單眼的照片。 Google 顯然也懂得「拍照傻瓜化」的道理，只是比起尋求專屬硬體來點更多技能樹，更喜歡用 AI 和各種堆疊演算法來解決問題。 這種思路很有趣，說白了，Google 希望讓機器自己學習如何才能拍得更好。  去年<U+00A0>Pixel 2 系列，Google 專門加入一顆名為「Pixel Visual Core」的自訂影像處理單元，這是 Google 與英特爾合作開發的 8 核心輔助處理器，用來加速各種與 AI 拍照相關的工作，比如 Pixel 系列一貫主打的 HDR+。 而<U+00A0>Pixel 3，這顆 Visual Core 核心也有更新，處理速度比去年快了 40%，意味著能更快處理各種繁雜的片源資料，在機器學習的幫助下還讓 Pixel 3 解決一些日常拍照的痛點。  首先是名為「Top Shot」的照片精選特<U+5FB4>，能在你按下快門時自動記錄前後數秒的影像，有點類似 iPhone 的 Live Photos，但此時 AI 會自動將「最佳時刻」打上標籤供你挑選，所以就算不小心拍到閉眼，也可以選擇其他畫面當作最終照片。  ▲「Night Sight」不僅適用於後置，也適用前置。（Source：Google） 至於伸手不見五指的場景，Google 的方案是「Night Sight」夜景模式，核心還是借助 HDR+ 的連續取樣和多幀合成，盡可能提高照片亮度，徹底解決「暗光拍不到」的問題。  （Source：Google） 為了強調此模式的出眾效果，Google 在發表會還對隔壁 iPhone XS 一番「吊打」，不知道蘋果的心情怎樣。 還有一個是「Super Res Zoom」，主要是取景變焦後圖片放大的情況，其實是將一些傳統單反的「像素偏移模式」用在變焦功能。  ▲ Engadget 日本使用 Pixel 3 拍攝的範本，放大框選部分。（Source：Engadget）  ▲ 框選部分放大。（Source：Engadget） 具體來說，Google 抓住我們取景時都會輕微抖動的小細節，自動根據手部運動移動感光元件，然後連續抓拍數張照片，再藉助演算法合成。 用這個方式，每個像素都可獲得足夠的 RGB 資訊，最終便能做成一張擁有超高解析度的照片。 按照<U+00A0>Android Central<U+00A0>的說法，哪怕放大 8 倍，Pixel 3 的變焦照片仍能保持和 Pixel 2 的<U+00A0>2 倍變焦一樣的清晰度。這意味著就算沒有獨立長焦鏡頭，Pixel 3 仍可拍出不亞於光學變焦效果的照片。 Google 延展的不只廣度，還有深度 我們已看過所有能選擇的鏡頭組合，單純加一顆鏡頭並沒有好處。 Pixel 3<U+00A0>發表會後，Google 產品副總裁<U+00A0>Brian Rakowski<U+00A0>說。在他看來，Pixel 手機已能透過感測器獲得夠多資訊，之後再用機器學習等方式，同樣能產生用戶所需的照片。  （Source：影片截圖） 本質上看，Google 嘗試用「計算攝影」（Computational Photography）概念，為傳統攝影引入 AI 機器學習等進階演算法，等同重新整理解析度、光照、對焦點和景深等這類影像資訊，突破單鏡頭的物理界限。 打個比方，以 Pixel 2 的<U+00A0>HDR+<U+00A0>為例，表面上看用手機拍照只是開啟取景器再<U+5494>嚓一聲，可暗地裡鏡頭在你開啟取景器後就開始採集工作了，這些資料會即時保留在緩衝區，最終由合成演算法呼叫出來。 除此之外，Google 還將圖片分割成一個個獨立方塊，保留高動態範圍和細節同時，也盡可能去除模糊、鬼影和噪點。  還有前文提到的「Top Shot」這種「先拍後選」模式，其實也受到計算攝影思維的影響，都是在用戶不知道的底層工作。 DPReview<U+00A0>近期採訪了 Pixel 相機產品經理 Isaac Reynolds 及計算攝影主管 Marc Levoy，他們表示，為了保證零延遲快門體驗，當初 Pixel 2 的安全快門值設為<U+00A0>1/15 秒，這樣哪怕是在最糟糕的暗光環境，HDR+ 也以保證<U+00A0>0.6 秒內合成最多<U+00A0>9 張影像；若光線充足狀態，可縮短到 150 毫秒。  （Source：Google AI） 很顯然，用戶是不會知道這些後段處理流程，呈現在眼前的只是最終成品。 而<U+00A0>Pixel 3 上，用於「Super Res Zoom」變焦模式的合成影像高達 15 張之多，「Night Sight」夜景模式更犧牲了零延遲快門。  （Source：Google） 和一些中國手機的超級夜景一樣，需要按快門時保持機身穩定，此時相機會捕捉最高 15 張照片並合成，每張照片的快門速度最低為 1/3 秒，由此獲得近 5 秒曝光效果的照片，因手抖糊掉的照片也會自動剔除。 不僅如此，考慮到黑暗環境下的糟糕光源，「Night Sight」拍攝照片也會借助機器學習來自動白平衡。  （Source：影片截圖） 另一個不得不說的是自 Google Pixel 2 時代就備受好評的人像模式，雖然這款手機並沒有雙鏡頭，但依舊可拍出不輸給同期雙鏡頭旗艦的虛化照片，藉助的是鏡頭感測器的 PDAF 雙像素特<U+5FB4>，擷取左右兩種視覺影像，得到簡單的深度資訊，然後再依靠影像分割技術，精準定位影像外框。 過程中<U+00A0>Google 花了不少心思訓練一個神經網路模型，會根據深度資訊分辨照片中哪些屬於人物，哪些屬於背景，畢竟只有分清前景和後景，演算法才能虛化處理正確區域，最終合成一張淺景深的照片。  ▲ 上排為機器學習參與後的深度資訊圖，下排是單純基於雙像素和立體演算法的深度資訊圖，背景椅子部分可看到明顯的差異。（Source：Google） 今年的 Pixel 3，Google 又調整深度對映演算法，透過機器學習抓取更精準的深度圖。 從上圖能看到，如果只是單純基於雙像素和立體演算法，碰到掏空的玩具球、玻璃杯或有網格欄杆這類前後景模糊的場景時，深度資訊很可能辨識出錯。 但機器學習參與後，虛化效果和範圍就跟以前不一樣了。 有了 AI 拍照，能讓 Pixel 手機變得和 iPhone 一樣流行嗎？ Google 是靠搜尋和工具業務起家，不是硬體公司，即使<U+00A0>Pixel 手機，整個重心都是圍繞服務和 AI 展開。 所以歷屆 Pixel 發表會，最出風頭的仍是 Google 的軟體服務。演講人不會介紹太多規格，更強調「只有 Pixel 手機才能用的功能和服務」，其中就有各種 AI 拍照的身影。 但面對蘋果、亞馬遜等巨頭步步緊逼，Google 又不得不做硬體，就像 Google 硬體負責人 Rick Osterloh 所說，他要找到更多方法讓 Google 智慧助手出現在人們眼前。所以你不僅能看到 Pixel 手機，還有各種智慧喇叭、耳機與平板電腦。 這並不是主流玩法，很多人看來智慧手機是硬體生意，推動消費者每年換手機的動力來自更好看的外觀、更強的處理器和更多鏡頭，各種手機產品的橫評也只是硬體參數比較，無法量化的軟體只能一筆帶過。 畢竟，除了 iPhone，其他主流手機都是用 Android 為底層，跑同樣 APK<U+00A0>應用，也唯獨只有硬體差異較大。 可是<U+00A0>Pixel 手機依舊和其他 Android 手機不一樣，這是 Google 親自參與，只有它能將 Android 系統改造成自己想要的樣子，不然你也不會看到那麼多基於底層的拍照演算法。 AI 加持下，沒人能猜到 Pixel 手機還能帶來多少我們不知道的玩法。  昨夜<U+306E>本<U+56FD><U+306E><U+767A>表<U+4F1A><U+3067><U+3072><U+3068>通<U+308A>見<U+3066><U+3057><U+307E><U+3063><U+305F><U+3051><U+308C><U+3069>、今日<U+306F> #Pixel3 <U+306E>日本<U+306E>報道<U+95A2>係者向<U+3051><U+306E><U+767A>表<U+4F1A><U+306B>行<U+3063><U+3066><U+304D><U+305F><U+3088>∼。 Pixel 3<U+306E><U+30AB><U+30E9><U+30D0><U+30EA>、 <U+2714><U+FE0F> Clearly White <U+2714><U+FE0F> Just Black <U+2714><U+FE0F> Not Pink <U+3063><U+3066>名前<U+304B><U+308F><U+3044><U+3044><U+3044>。<U+304C><U+30DE><U+30C3><U+30C8><U+306A>仕上<U+3052><U+306B><U+306A><U+3063><U+3066><U+308B><U+306E><U+3082><U+304A><U+3057><U+3083><U+308C>。 #madebygoogle pic.twitter.com/gYFLWubrZX — Nagisa Ichikawa / THE GUILD (@nagiko726) 2018年10月10日  但 AI 並非萬能，Pixel 3 依舊有只能靠硬體達成的特<U+5FB4>。比如說新加入的 800 萬前置廣角鏡頭，就是專門用來拍集體照和大場景自拍，這兩種場景都沒辦法靠傳統自拍鏡頭。 還有那顆 Visual Core 核心，如果沒有它的協助，Pixel 3 的 AI 拍照也無從談起。 追根究柢，手機<U+00A0>AI 仍要靠足夠計算力驅動，沒有優秀的硬體為基礎，軟體體驗顯然得打對折。 但 Google 顯然為手機攝影帶來另一種發展方向，這也給原本就有強大物理硬體加持的同僚更多啟示。當然，也無疑讓消費者對手機拍照有更高的期待。 （本文由 愛范兒 授權轉載；首圖來源：達志影像） 延伸閱讀： Made by Google 三款新品紐約發表，台灣列入 Pixel 3 手機首發名單 
