
				一直以來，許多腫瘤的分類診斷一定要仰賴專業病理學家在顯微鏡下耗時仔細觀察來完成，而今日，一項結合訓練機器學習的重大突破，讓這項重要工作能縮短至數秒內完成。近期發表於《Nature Medicine》期刊的一項最新研究，美國紐約大學（New York University）研究團隊重新訓練現成的 Google 深度學習（deep learning）演算法（algorithm），辨識兩種最常見的肺癌類型──肺腺癌（adenocarcinoma）和鱗狀細胞癌（squamous cell carcinoma），辨識準確度可達 97%。團隊使用的這項人工智慧科技，與上傳至 Google 線上服務的圖片庫以辨識圖片中的面孔、動物和物體技術相同，過去 Google 這項科技也曾應用在疾病診斷，包括糖尿病引發之失明和心臟疾病。而這次，紐約大學的神經網路（neural network）開發出一項病理學家從未嘗試過的診斷分析方式──藉由腫瘤影像照片辨識基因突變。 「我認為此項新發現不僅展示出 AI 相當於人的表現，而是 AI 能更進一步提供人類專家無法提供的洞察力（insights）。」紐約大學醫學院的病理學家，同時也是此篇研究的主要作者 Aristotelis Tsirigos 說。 Tsirigos 團隊利用 Google Inception v3──Google 訓練辨識一千種不同種類物體的開源（open-source）演算法。為了訓練這個演算法區分出惡性和健康的組織圖像，研究團隊利用病患組織檢體公共資料庫成千上萬的癌症基因體圖譜（The Cancer Genome Atlas，TCGA）影像。首先，團隊成功訓練 Inception 達到 99% 準確度辨識惡性細胞的能力，接下來，再訓練 Inception 辨識肺腺癌和鱗狀細胞癌這兩種不同類型的肺癌，這是當今最普遍的兩種肺癌類型，每年於美國奪走將近 15 萬人生命。儘管這兩種肺癌的腫瘤組織細胞在顯微鏡下成像十分相似，治療卻相當不同，正確的治療對病患的生死存亡來說有十分重要的影響。 臨床檢測的演算法最重要的應是可靠性 接著，團隊使用不同資料庫（紐約大學醫院的癌症病患）檢體資料來檢測 Inception 的分析能力，雖然結果顯示準確度下降一些，但依然能正確診斷影像（準確度介於 83%~97%）。Tsirigos 表示，他們對這樣的結果並不訝異，因為研究團隊已預期來自醫院的檢體會有較多「雜訊」（noise），如炎症反應（inflammation）、死亡組織和白血球等等，且這些檢體處理過程也與冷凍癌症基因圖譜（TCGA）檢體不同，而改善準確度僅需透過病理學家進一步註解切片的特徵，演算法就能很快習得、分辨。 實際上，Inception 可辨識組織切片基因突變的這項能力，並不是人為教授而來，而是演算法自我習得。Tsirigos 團隊提供 Inception 的資訊為 TCGA 資料庫每個腫瘤的基因檔案和切片影像，Inception 藉此建立分析演算，當團隊以其他新影像測試時，Inception 不僅能辨識包含惡性組織的圖片，還能夠偵測該組織檢體的基因突變，此神經網路能發現腫瘤檢體外觀極細微的改變，這甚至是組織病理學家未能以肉眼看見的。「這些腫瘤驅使的突變，似乎有一種演算法可偵測到的顯微作用。我們現在還不知道這些細微的改變為何，但它們就隱藏於演算法中，沒人知道如何擷取出來。」 這就是深度學習的黑箱（black box）問題，有人爭議，這些演算法在廣泛應用之前必須完全透明化，不然該如何掌握失誤的可能性，尤其是攸關病患生死的應用。康乃爾大學精準醫學教授 Olivier Elemento 表示，當一項臨床檢測可達 99% 的準確性而不加以利用，是件愚蠢的事。「坦白說，像這樣應用到臨床檢測的演算法，全面解讀的功能並非必要，最重要的應是可靠性。」但近乎百分百的可靠度並非易事，不同醫院處理腫瘤檢體的工具和流程皆不同，訓練一種演算法應用所有不同情況會相當困難。 但這正是 Tsirigos 研究團隊計畫達成的目標，接下來幾個月，他們會繼續以更多不同來源的資料訓練 AI，若發展順利，他們會考慮成立公司並向美國 FDA 提出申請。由於時間和成本考量，目前在美國，腫瘤檢體的序列分析並非標準照護的流程，但試想，若能透過寄送腫瘤檢體的數位影像，立即取得診斷結果和治療選擇，這將為病患和醫護人員省下許多時間和人力。 「最大的問題是，這項分析方式是否夠可靠到取代現行的操作方式？」史丹佛癌症研究機構（Stanford Cancer Institute）生物資訊主任 Daniel Rubin 說。預期未來還需要很多驗證確效的工作，但這項發現的確指出一個重要的方向，就是未來病理學家與電腦功能整合的可能性，「這項發表真正展示的是，影像中可被擷取的資訊遠超過人類直接自行解讀的部分。」 這正是數位病理學更進階的主題，有了 Google 和其他公司開發、開放源碼的演算法，研究團隊現在可更容易開創自己的 AI，僅需稍微客製化，就能分析成千上萬的生物醫學影像數據，不限於腫瘤影像。 Tsirigos 接受訪問時，被問到會不會很難找到自願的病理學家幫忙訓練他們的癌症分類系統，他笑著說，一開始他們都不敢請 NYU 同事加入研究，因為這就像在幫忙製造未來的競爭者，但最後卻出乎預料進行得相當順利，因為大家都很好奇 Inception 能做到什麼程度，並不只在肺癌應用，也包括他們自身的研究。Tsirigos 說，大家並沒有擔心自己的工作會被取代，反而很高興能回答比機器更深入的問題，「就讓機器幫我們做到辨識部分，剩下還有很多醫療工作要靠人類來完成。」 Google AI Tool Identifies a Tumor’s Mutations From an Image Classification and mutation prediction from non–small cell lung cancer histopathology images using deep learning （首圖為 AI 辨識的肺癌腫類，紅色為鱗狀細胞癌，藍色為肺鱗狀細胞癌，灰色為正常肺組織。來源：紐約大學） 				
				
